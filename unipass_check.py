import os
import re
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs
from datetime import datetime

# ğŸ“Œ Notion í™˜ê²½ë³€ìˆ˜
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
NOTION_DATABASE_ID = os.getenv("NOTION_DATABASE_ID")

# ğŸ“Œ Notion ê³µí†µ í—¤ë”
NOTION_HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": "2022-06-28",
    "Content-Type": "application/json",
}

# ğŸ“Œ ê³µí†µ User-Agent (ê°€ë” ì‚¬ì´íŠ¸ì—ì„œ UA ì—†ìœ¼ë©´ ë§‰ëŠ” ê²½ìš° ìˆìŒ)
UA_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123 Safari/537.36"
}


def is_probably_number(s: str) -> bool:
    if not s:
        return False
    return bool(re.fullmatch(r"\d{8,30}", s.strip()))


def get_tracking_items():
    """
    Notion DBì—ì„œ ì¡°íšŒë§í¬, ì„±í•¨, page_id ê°€ì ¸ì˜¤ê¸°
    - ì¡°íšŒë§í¬ê°€ URLì´ë©´: asap ë§í¬ë¡œ íŒë‹¨
    - ì¡°íšŒë§í¬ê°€ ìˆ«ìë©´: House B/L(ì†¡ì¥ë²ˆí˜¸)ë¡œ íŒë‹¨ (Tradlinx ì¡°íšŒ)
    """
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
    response = requests.post(url, headers=NOTION_HEADERS, json={})

    print("[DEBUG] Notion status:", response.status_code)
    try:
        data = response.json()
    except Exception as e:
        print("[DEBUG] Notion ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨:", e, response.text)
        return []

    if "results" not in data:
        print("[DEBUG] Notion ì‘ë‹µì— 'results' í‚¤ê°€ ì—†ìŒ. ì „ì²´ ì‘ë‹µ:")
        print(data)
        return []

    items = []
    for result in data["results"]:
        props = result["properties"]

        full_url = props.get("ì¡°íšŒë§í¬", {}).get("url", "") or ""
        name = props.get("ì„±í•¨", {}).get("rich_text", [])
        name_text = name[0]["plain_text"] if name else ""
        page_id = result["id"]

        raw = (full_url or "").strip()

        # 1) ASAP ë§í¬(ê¸°ì¡´ ë°©ì‹)
        if raw.startswith("http"):
            parsed_url = urlparse(raw)
            query_params = parse_qs(parsed_url.query)
            customs_code = query_params.get("code", [""])[0]
            invoice_no = query_params.get("invoice", [""])[0]

            if customs_code and invoice_no:
                items.append({
                    "type": "asap",
                    "code": customs_code,
                    "invoice": invoice_no,
                    "page_id": page_id,
                    "name": name_text,
                    "raw": raw,
                })
            else:
                items.append({
                    "type": "unknown",
                    "page_id": page_id,
                    "name": name_text,
                    "raw": raw,
                })

        # 2) ìˆ«ìë§Œ ìˆìœ¼ë©´ -> Tradlinx (í•˜ì´ì› House B/L)
        elif is_probably_number(raw):
            items.append({
                "type": "tradlinx",
                "bl_no": raw,
                "page_id": page_id,
                "name": name_text,
                "raw": raw,
            })

        else:
            items.append({
                "type": "unknown",
                "page_id": page_id,
                "name": name_text,
                "raw": raw,
            })

    return items


def check_unipass_status_asap(code, invoice):
    """(ê¸°ì¡´) ASAP ìœ ë‹ˆíŒ¨ìŠ¤ ì²˜ë¦¬ë‹¨ê³„ + ì²˜ë¦¬ì¼ì‹œ ê°€ì ¸ì˜¤ê¸°"""
    url = f"https://asap-china.com/guide/unipass_delivery.php?code={code}&invoice={invoice}"
    response = requests.get(url, headers=UA_HEADERS, timeout=20)
    soup = BeautifulSoup(response.text, "html.parser")

    tables = soup.find_all("table")
    if len(tables) < 2:
        return []

    table = tables[1]
    rows = table.find_all("tr")[1:]  # í—¤ë” ì œì™¸

    steps = []
    for row in rows:
        tds = row.find_all("td")
        if len(tds) > 2:
            step_text = tds[1].get_text(strip=True)
            time_text = tds[2].get_text(strip=True)
            steps.append({"step": step_text, "time": time_text})

    return steps


def fetch_tradlinx_steps(bl_no: str, year: int):
    """
    Tradlinx í˜ì´ì§€ì—ì„œ ì²˜ë¦¬ë‹¨ê³„(step) / ì²˜ë¦¬ì¼ì‹œ(time) íŒŒì‹±
    - ë„¤ê°€ ì˜¬ë¦° HTML ê¸°ì¤€: cargo-process ì•ˆì— process-detail ë°˜ë³µ
      li.tp-cd = ë‹¨ê³„ëª…
      li.rl-br-dttm = ì¼ì‹œ
    """
    url = f"https://www.tradlinx.com/ko/unipass?type=2&blNo={bl_no}&blYr={year}"
    r = requests.get(url, headers=UA_HEADERS, timeout=25)
    html = r.text

    soup = BeautifulSoup(html, "html.parser")
    cargo = soup.find("div", class_="cargo-process")
    if not cargo:
        # (í™•ì‹¤í•˜ì§€ ì•ŠìŒ) ë§Œì•½ JS ë Œë”ë§ì´ë¼ë©´ ì—¬ê¸°ì„œ ë¹ˆ í˜ì´ì§€ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
        return []

    steps = []
    for pd in cargo.find_all("div", class_="process-detail"):
        step_el = pd.select_one("ul li.tp-cd")
        time_el = pd.select_one("ul li.rl-br-dttm")
        if step_el and time_el:
            step = step_el.get_text(strip=True)
            time = time_el.get_text(strip=True)
            steps.append({"step": step, "time": time})

    return steps


def check_unipass_status_tradlinx(bl_no: str):
    """
    TradlinxëŠ” blYr(ë…„ë„)ê°€ í•„ìš”í•´ì„œ:
    - ì˜¬í•´ ë¨¼ì € ì‹œë„
    - ì•ˆ ë‚˜ì˜¤ë©´ ì‘ë…„ ì‹œë„ (ì—°ë§/ì—°ì´ˆ ê±¸ì³ìˆì„ ìˆ˜ ìˆì–´ì„œ)
    """
    this_year = datetime.now().year
    for y in [this_year, this_year - 1]:
        steps = fetch_tradlinx_steps(bl_no, y)
        if steps:
            return steps
    return []


def update_notion_status(page_id, processed_at):
    """
    ë…¸ì…˜ í˜ì´ì§€ì˜ 'ë°˜ì…ìƒíƒœ'ë¥¼
    'ì‹¬ì‚¬ì™„ë£Œ [ì²˜ë¦¬ì¼ì‹œ]' í˜•íƒœë¡œ ì—…ë°ì´íŠ¸
    """
    status_text = f"ì‹¬ì‚¬ì™„ë£Œ [{processed_at}]"

    url = f"https://api.notion.com/v1/pages/{page_id}"
    payload = {
        "properties": {
            "ë°˜ì…ìƒíƒœ": {
                "rich_text": [{"text": {"content": status_text}}]
            }
        }
    }

    resp = requests.patch(url, headers=NOTION_HEADERS, json=payload)
    if resp.status_code == 200:
        print(f"[ğŸŸ¢ ë°˜ì…ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ] {page_id} â†’ {status_text}")
    else:
        print(f"[âš ï¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨] {resp.status_code} / {resp.text}")


def main():
    print("[ğŸš€ ìœ ë‹ˆíŒ¨ìŠ¤ ìë™ ì¶”ì  ì‹œì‘]\n")

    items = get_tracking_items()
    any_found = False

    for it in items:
        name = it.get("name", "")
        raw = it.get("raw", "")

        if it["type"] == "asap":
            invoice = it["invoice"]
            print(f"[ğŸ” ê²€ì‚¬ ì¤‘ - ASAP] {invoice} / {name}")
            steps = check_unipass_status_asap(it["code"], invoice)

        elif it["type"] == "tradlinx":
            bl_no = it["bl_no"]
            print(f"[ğŸ” ê²€ì‚¬ ì¤‘ - TRADLINX] {bl_no} / {name}")
            steps = check_unipass_status_tradlinx(bl_no)

        else:
            print(f"[âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹] {name} / {raw}")
            continue

        target = next((s for s in steps if s["step"] == "í†µê´€ëª©ë¡ì‹¬ì‚¬ì™„ë£Œ"), None)
        if target:
            processed_at = target["time"]
            key = it.get("invoice") or it.get("bl_no") or raw
            print(f"[ğŸ‰ í†µê´€ëª©ë¡ì‹¬ì‚¬ì™„ë£Œ ë°œê²¬] {key} / {name} / {processed_at}")
            update_notion_status(it["page_id"], processed_at)
            any_found = True

    if not any_found:
        print("[â„¹ï¸ ì•„ì§ ì‹¬ì‚¬ì™„ë£Œ ì—†ìŒ]")


if __name__ == "__main__":
    main()
